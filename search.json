[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pyssed ",
    "section": "",
    "text": "The goal of pyssed is to implement the Mixture Adaptive Design (MAD), as proposed by Liang and Bojinov. MAD is an experimental design for multi-armed bandit algorithms that enables anytime-valid inference on the Average Treatment Effect (ATE).\n\nIntuitively, MAD “mixes” any bandit algorithm with a Bernoulli design, where at each time step, the probability of assigning a unit via the Bernoulli design is determined by a user-specified deterministic sequence that can converge to zero. This sequence lets managers directly control the trade-off between regret minimization and inferential precision. Under mild conditions on the rate the sequence converges to zero, [MAD] provides a confidence sequence that is asymptotically anytime-valid and guaranteed to shrink around the true ATE. Hence, when the true ATE converges to a non-zero value, the MAD confidence sequence is guaranteed to exclude zero in finite time. Therefore, the MAD enables managers to stop experiments early while ensuring valid inference, enhancing both the efficiency and reliability of adaptive experiments.\n\n\n\npyssed can be installed from PyPI with:\npip install pyssed\nor from GitHub with:\npip install git+https://github.com/dmolitor/pyssed\n\n\n\nWe’ll simulate an experiment with three treatment arms and one control arm using Thompson Sampling (TS) as the bandit algorithm. We’ll demonstrate how MAD enables unbiased ATE estimation for all treatments while maintaining valid confidence sequences.\nFirst, import the necessary packages:\n\nimport numpy as np\nimport pandas as pd\nimport plotnine as pn\nfrom pyssed import Bandit, MAD\nfrom typing import Callable, Dict\n\ngenerator = np.random.default_rng(seed=123)\n\n\n\nNext, define a function to generate outcomes (rewards) for each experiment arm:\n\ndef reward_fn(arm: int) -&gt; float:\n    values = {\n        0: generator.binomial(1, 0.5),  # Control arm\n        1: generator.binomial(1, 0.6),  # ATE = 0.1\n        2: generator.binomial(1, 0.7),  # ATE = 0.2\n        3: generator.binomial(1, 0.72), # ATE = 0.22\n    }\n    return values[arm]\n\nWe design the experiment so Arm 1 has a small ATE (0.1), while Arms 2 and 3 have larger ATEs (0.2 and 0.22) that are very similar.\n\n\n\nWe’ll now implement TS for binary data, modeling each arm’s outcomes as drawn from a Bernoulli with an unknown parameter \\(\\theta\\), where \\(\\theta\\) follows a Beta(\\(\\alpha\\)=1, \\(\\beta\\)=1) prior (a uniform prior).\nTo use MAD, pyssed requires the bandit algorithm to be a class inheriting from pyssed.Bandit, which requires the bandit class to implement the following key methods:\n\ncontrol(): Returns the control arm index.\nk(): Returns the number of arms.\nprobabilities(): Computes arm assignment probabilities.\nreward(arm): Computes the reward for a selected arm.\nt() Returns the current time step.\n\nFor full details, see the pyssed.Bandit documentation.\nThe following is an example TS implementation:\n\nclass TSBernoulli(Bandit):\n    \"\"\"\n    A class for implementing Thompson Sampling on Bernoulli data\n    \"\"\"\n    def __init__(self, k: int, control: int, reward: Callable[[int], float]):\n        self._control = control\n        self._k = k\n        self._means = {x: 0. for x in range(k)}\n        self._params = {x: {\"alpha\": 1, \"beta\": 1} for x in range(k)}\n        self._rewards = {x: [] for x in range(k)}\n        self._reward_fn = reward\n        self._t = 1\n\n    def control(self) -&gt; int:\n        return self._control\n    \n    def k(self) -&gt; int:\n        return self._k\n    \n    def probabilities(self) -&gt; Dict[int, float]:\n        samples = np.column_stack([\n            np.random.beta(\n                a=self._params[idx][\"alpha\"],\n                b=self._params[idx][\"beta\"],\n                size=1000\n            )\n            for idx in range(self.k())\n        ])\n        max_indices = np.argmax(samples, axis=1)\n        probs = {\n            idx: np.sum(max_indices == i) / 1000\n            for i, idx in enumerate(range(self.k()))\n        }\n        return probs\n    \n    def reward(self, arm: int) -&gt; float:\n        outcome = self._reward_fn(arm)\n        self._rewards[arm].append(outcome)\n        if outcome == 1:\n            self._params[arm][\"alpha\"] += 1\n        else:\n            self._params[arm][\"beta\"] += 1\n        self._means[arm] = (\n            self._params[arm][\"alpha\"]\n            /(self._params[arm][\"alpha\"] + self._params[arm][\"beta\"])\n        )\n        return outcome\n\n    def t(self) -&gt; int:\n        step = self._t\n        self._t += 1\n        return step\n\nWith our TS bandit algorithm implemented, we can now wrap it in the MAD experimental design for inference on the ATEs!\n\n\n\nFor our MAD design, we need a function that takes the time step \\(t\\) and computes a sequence converging to 0. The key requirement is that this sequence must decay slower than \\(1/(t^{1/4})\\).\nIntuitively, a sequence of \\(1/t^0 = 1\\) corresponds to Bernoulli randomization, while a sequence of \\(1/(t^{0.24})\\) closely follows the TS assignment policy.\nIn this example, we use \\(1/(t^{0.24})\\) as our sequence. Additionally, we estimate 95% confidence sequences, setting our test size \\(\\alpha=0.05\\). We run the experiment for 20,000 iterations (t_star = 20000).\n\nexperiment = MAD(\n    bandit=TSBernoulli(k=4, control=0, reward=reward_fn),\n    alpha=0.05,\n    delta=lambda x: 1./(x**0.24),\n    t_star=int(20e3)\n)\nexperiment.fit(verbose=False)\n\n\n\n\nNow, to examine the results we can print a summary of the ATEs and their corresponding confidence sequences at the end of the experiment:\n\nexperiment.summary()\n\nTreatment effect estimates:\n- Arm 1: 0.043 (-0.10817, 0.19444)\n- Arm 2: 0.146 (0.03005, 0.26281)\n- Arm 3: 0.174 (0.06821, 0.27902)\n\n\nWe can also extract this summary into a pandas DataFrame:\n\nexperiment.estimates()\n\n\n\n\n\narm\nate\nlb\nub\n\n\n\n\n0\n1\n0.043137\n-0.108165\n0.194438\n\n\n1\n2\n0.146426\n0.030046\n0.262807\n\n\n2\n3\n0.173614\n0.068206\n0.279022\n\n\n\n\n3 rows × 4 columns\n\n\n\n\n\nWe can also visualize the ATE estimates and confidence sequences for each treatment arm over time.\n\n(\n    experiment.plot_ate()\n    + pn.coord_cartesian(ylim=(-.5, 1.0))\n    + pn.geom_hline(\n        mapping=pn.aes(yintercept=\"ate\", color=\"factor(arm)\"),\n        data=pd.DataFrame({\"arm\": [1, 2, 3], \"ate\": [0.1, 0.2, 0.22]}),\n        linetype=\"dotted\"\n    )\n    + pn.theme(strip_text=pn.element_blank())\n)\n\n\n\n\n\n\n\n\nThe ATE estimates converge toward the ground truth, and the confidence sequences maintain valid coverage!\nWe can also examine the algorithm’s sample assignment strategy over time.\n\nexperiment.plot_sample_assignment()\n\n\n\n\n\n\n\n\nDue to the TS algorithm, most samples go to the optimal Arm 3 and secondary Arm 2, with some random exploration in Arms 0 and 1.\nSimilarly, we can plot the total sample assignments per arm.\n\nexperiment.plot_n()\n\n\n\n\n\n\n\n\n\n\n\nAs noted above, setting the time-diminishing sequence \\(\\delta_t = 1/t^0 = 1\\) results in a fully randomized design. We can easily demonstrate this:\n\nexp_bernoulli = MAD(\n    bandit=TSBernoulli(k=4, control=0, reward=reward_fn),\n    alpha=0.05,\n    delta=lambda _: 1.,\n    t_star=int(20e3)\n)\nexp_bernoulli.fit(verbose=False)\n\nAs before, we can plot the convergence of the estimated ATEs to the ground truth:\n\n(\n    exp_bernoulli.plot_ate()\n    + pn.coord_cartesian(ylim=(-.1, 0.6))\n    + pn.geom_hline(\n        mapping=pn.aes(yintercept=\"ate\", color=\"factor(arm)\"),\n        data=pd.DataFrame({\"arm\": [1, 2, 3], \"ate\": [0.1, 0.2, 0.22]}),\n        linetype=\"dotted\"\n    )\n    + pn.theme(strip_text=pn.element_blank())\n)\n\n\n\n\n\n\n\n\nAnd we can verify fully random assignment:\n\nexp_bernoulli.plot_n()"
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "pyssed ",
    "section": "",
    "text": "pyssed can be installed from PyPI with:\npip install pyssed\nor from GitHub with:\npip install git+https://github.com/dmolitor/pyssed"
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "pyssed ",
    "section": "",
    "text": "We’ll simulate an experiment with three treatment arms and one control arm using Thompson Sampling (TS) as the bandit algorithm. We’ll demonstrate how MAD enables unbiased ATE estimation for all treatments while maintaining valid confidence sequences.\nFirst, import the necessary packages:\n\nimport numpy as np\nimport pandas as pd\nimport plotnine as pn\nfrom pyssed import Bandit, MAD\nfrom typing import Callable, Dict\n\ngenerator = np.random.default_rng(seed=123)\n\n\n\nNext, define a function to generate outcomes (rewards) for each experiment arm:\n\ndef reward_fn(arm: int) -&gt; float:\n    values = {\n        0: generator.binomial(1, 0.5),  # Control arm\n        1: generator.binomial(1, 0.6),  # ATE = 0.1\n        2: generator.binomial(1, 0.7),  # ATE = 0.2\n        3: generator.binomial(1, 0.72), # ATE = 0.22\n    }\n    return values[arm]\n\nWe design the experiment so Arm 1 has a small ATE (0.1), while Arms 2 and 3 have larger ATEs (0.2 and 0.22) that are very similar.\n\n\n\nWe’ll now implement TS for binary data, modeling each arm’s outcomes as drawn from a Bernoulli with an unknown parameter \\(\\theta\\), where \\(\\theta\\) follows a Beta(\\(\\alpha\\)=1, \\(\\beta\\)=1) prior (a uniform prior).\nTo use MAD, pyssed requires the bandit algorithm to be a class inheriting from pyssed.Bandit, which requires the bandit class to implement the following key methods:\n\ncontrol(): Returns the control arm index.\nk(): Returns the number of arms.\nprobabilities(): Computes arm assignment probabilities.\nreward(arm): Computes the reward for a selected arm.\nt() Returns the current time step.\n\nFor full details, see the pyssed.Bandit documentation.\nThe following is an example TS implementation:\n\nclass TSBernoulli(Bandit):\n    \"\"\"\n    A class for implementing Thompson Sampling on Bernoulli data\n    \"\"\"\n    def __init__(self, k: int, control: int, reward: Callable[[int], float]):\n        self._control = control\n        self._k = k\n        self._means = {x: 0. for x in range(k)}\n        self._params = {x: {\"alpha\": 1, \"beta\": 1} for x in range(k)}\n        self._rewards = {x: [] for x in range(k)}\n        self._reward_fn = reward\n        self._t = 1\n\n    def control(self) -&gt; int:\n        return self._control\n    \n    def k(self) -&gt; int:\n        return self._k\n    \n    def probabilities(self) -&gt; Dict[int, float]:\n        samples = np.column_stack([\n            np.random.beta(\n                a=self._params[idx][\"alpha\"],\n                b=self._params[idx][\"beta\"],\n                size=1000\n            )\n            for idx in range(self.k())\n        ])\n        max_indices = np.argmax(samples, axis=1)\n        probs = {\n            idx: np.sum(max_indices == i) / 1000\n            for i, idx in enumerate(range(self.k()))\n        }\n        return probs\n    \n    def reward(self, arm: int) -&gt; float:\n        outcome = self._reward_fn(arm)\n        self._rewards[arm].append(outcome)\n        if outcome == 1:\n            self._params[arm][\"alpha\"] += 1\n        else:\n            self._params[arm][\"beta\"] += 1\n        self._means[arm] = (\n            self._params[arm][\"alpha\"]\n            /(self._params[arm][\"alpha\"] + self._params[arm][\"beta\"])\n        )\n        return outcome\n\n    def t(self) -&gt; int:\n        step = self._t\n        self._t += 1\n        return step\n\nWith our TS bandit algorithm implemented, we can now wrap it in the MAD experimental design for inference on the ATEs!\n\n\n\nFor our MAD design, we need a function that takes the time step \\(t\\) and computes a sequence converging to 0. The key requirement is that this sequence must decay slower than \\(1/(t^{1/4})\\).\nIntuitively, a sequence of \\(1/t^0 = 1\\) corresponds to Bernoulli randomization, while a sequence of \\(1/(t^{0.24})\\) closely follows the TS assignment policy.\nIn this example, we use \\(1/(t^{0.24})\\) as our sequence. Additionally, we estimate 95% confidence sequences, setting our test size \\(\\alpha=0.05\\). We run the experiment for 20,000 iterations (t_star = 20000).\n\nexperiment = MAD(\n    bandit=TSBernoulli(k=4, control=0, reward=reward_fn),\n    alpha=0.05,\n    delta=lambda x: 1./(x**0.24),\n    t_star=int(20e3)\n)\nexperiment.fit(verbose=False)\n\n\n\n\nNow, to examine the results we can print a summary of the ATEs and their corresponding confidence sequences at the end of the experiment:\n\nexperiment.summary()\n\nTreatment effect estimates:\n- Arm 1: 0.043 (-0.10817, 0.19444)\n- Arm 2: 0.146 (0.03005, 0.26281)\n- Arm 3: 0.174 (0.06821, 0.27902)\n\n\nWe can also extract this summary into a pandas DataFrame:\n\nexperiment.estimates()\n\n\n\n\n\narm\nate\nlb\nub\n\n\n\n\n0\n1\n0.043137\n-0.108165\n0.194438\n\n\n1\n2\n0.146426\n0.030046\n0.262807\n\n\n2\n3\n0.173614\n0.068206\n0.279022\n\n\n\n\n3 rows × 4 columns\n\n\n\n\n\nWe can also visualize the ATE estimates and confidence sequences for each treatment arm over time.\n\n(\n    experiment.plot_ate()\n    + pn.coord_cartesian(ylim=(-.5, 1.0))\n    + pn.geom_hline(\n        mapping=pn.aes(yintercept=\"ate\", color=\"factor(arm)\"),\n        data=pd.DataFrame({\"arm\": [1, 2, 3], \"ate\": [0.1, 0.2, 0.22]}),\n        linetype=\"dotted\"\n    )\n    + pn.theme(strip_text=pn.element_blank())\n)\n\n\n\n\n\n\n\n\nThe ATE estimates converge toward the ground truth, and the confidence sequences maintain valid coverage!\nWe can also examine the algorithm’s sample assignment strategy over time.\n\nexperiment.plot_sample_assignment()\n\n\n\n\n\n\n\n\nDue to the TS algorithm, most samples go to the optimal Arm 3 and secondary Arm 2, with some random exploration in Arms 0 and 1.\nSimilarly, we can plot the total sample assignments per arm.\n\nexperiment.plot_n()\n\n\n\n\n\n\n\n\n\n\n\nAs noted above, setting the time-diminishing sequence \\(\\delta_t = 1/t^0 = 1\\) results in a fully randomized design. We can easily demonstrate this:\n\nexp_bernoulli = MAD(\n    bandit=TSBernoulli(k=4, control=0, reward=reward_fn),\n    alpha=0.05,\n    delta=lambda _: 1.,\n    t_star=int(20e3)\n)\nexp_bernoulli.fit(verbose=False)\n\nAs before, we can plot the convergence of the estimated ATEs to the ground truth:\n\n(\n    exp_bernoulli.plot_ate()\n    + pn.coord_cartesian(ylim=(-.1, 0.6))\n    + pn.geom_hline(\n        mapping=pn.aes(yintercept=\"ate\", color=\"factor(arm)\"),\n        data=pd.DataFrame({\"arm\": [1, 2, 3], \"ate\": [0.1, 0.2, 0.22]}),\n        linetype=\"dotted\"\n    )\n    + pn.theme(strip_text=pn.element_blank())\n)\n\n\n\n\n\n\n\n\nAnd we can verify fully random assignment:\n\nexp_bernoulli.plot_n()"
  },
  {
    "objectID": "reference/Bandit.html",
    "href": "reference/Bandit.html",
    "title": "Bandit",
    "section": "",
    "text": "Bandit()\nAn abstract class for Bandit algorithms used in the MAD algorithm.\nEach bandit algorithm that inherits from this class must implement all the abstract methods defined in this class.\n\n\nSee the detailed method documentation for in-depth explanations.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncontrol\nGet the index of the bandit control arm.\n\n\nk\nGet the number of bandit arms.\n\n\nprobabilities\nCalculate bandit arm assignment probabilities.\n\n\nreward\nCalculate the reward for a selected bandit arm.\n\n\nt\nGet the current time step of the bandit.\n\n\n\n\n\nBandit.control()\nGet the index of the bandit control arm.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nint\nThe index of the arm that is the control arm. E.g. if the bandit is a 3-arm bandit with the first arm being the control arm, this should return the value 0.\n\n\n\n\n\n\n\nBandit.k()\nGet the number of bandit arms.\nint The number of arms in the bandit.\n\n\n\nBandit.probabilities()\nCalculate bandit arm assignment probabilities.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nDict[int, float]\nA dictionary where keys are arm indices and values are the corresponding probabilities. For example, if the bandit algorithm is UCB with three arms, and the third arm has the maximum confidence bound, then this should return the following dictionary: {0: 0., 1: 0., 2: 1.}, since UCB is deterministic.\n\n\n\n\n\n\n\nBandit.reward(arm)\nCalculate the reward for a selected bandit arm.\nReturns the reward for a selected arm.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\narm\nint\nThe index of the selected bandit arm.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nThe resulting reward.\n\n\n\n\n\n\n\nBandit.t()\nGet the current time step of the bandit.\nThis method returns the current time step of the bandit, and then increments the time step by 1. E.g. if the bandit has completed 9 iterations, this should return the value 10. Time steps start at 1, not 0.\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nint\nThe current time step."
  },
  {
    "objectID": "reference/Bandit.html#notes",
    "href": "reference/Bandit.html#notes",
    "title": "Bandit",
    "section": "",
    "text": "See the detailed method documentation for in-depth explanations."
  },
  {
    "objectID": "reference/Bandit.html#methods",
    "href": "reference/Bandit.html#methods",
    "title": "Bandit",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncontrol\nGet the index of the bandit control arm.\n\n\nk\nGet the number of bandit arms.\n\n\nprobabilities\nCalculate bandit arm assignment probabilities.\n\n\nreward\nCalculate the reward for a selected bandit arm.\n\n\nt\nGet the current time step of the bandit.\n\n\n\n\n\nBandit.control()\nGet the index of the bandit control arm.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nint\nThe index of the arm that is the control arm. E.g. if the bandit is a 3-arm bandit with the first arm being the control arm, this should return the value 0.\n\n\n\n\n\n\n\nBandit.k()\nGet the number of bandit arms.\nint The number of arms in the bandit.\n\n\n\nBandit.probabilities()\nCalculate bandit arm assignment probabilities.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nDict[int, float]\nA dictionary where keys are arm indices and values are the corresponding probabilities. For example, if the bandit algorithm is UCB with three arms, and the third arm has the maximum confidence bound, then this should return the following dictionary: {0: 0., 1: 0., 2: 1.}, since UCB is deterministic.\n\n\n\n\n\n\n\nBandit.reward(arm)\nCalculate the reward for a selected bandit arm.\nReturns the reward for a selected arm.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\narm\nint\nThe index of the selected bandit arm.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nThe resulting reward.\n\n\n\n\n\n\n\nBandit.t()\nGet the current time step of the bandit.\nThis method returns the current time step of the bandit, and then increments the time step by 1. E.g. if the bandit has completed 9 iterations, this should return the value 10. Time steps start at 1, not 0.\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nint\nThe current time step."
  },
  {
    "objectID": "reference/MAD.html",
    "href": "reference/MAD.html",
    "title": "MAD",
    "section": "",
    "text": "MAD(self, bandit, alpha, delta, t_star)\nA class implementing Liang and Bojinov’s Mixture-Adaptive Design (MAD).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbandit\nBandit\nThe underlying bandit algorithm on which the MAD design operates. This bandit class must implement several crucial methods/attributes. For more details on how to create a custom Bandit object, see the documentation of the pyssed.Bandit class.\nrequired\n\n\nalpha\nfloat\nThe size of the statistical test (testing for non-zero ATEs).\nrequired\n\n\ndelta\nCallable[[int], float]\nA function that generates the real-valued sequence delta_t in Liang and Bojinov (Definition 4 - Mixture Adaptive Design). This sequence determines the amount of random exploration that is infused into the bandit design, and it should converge to 0 slower than 1/t^(1/4) where t denotes the time step in {0, … n}. This function should intake an integer (t) and output a float (the corresponding delta_t).\nrequired\n\n\nt_star\nint\nThe time-step at which we want to optimize the CSs to be tightest. E.g. Liang and Bojinov set this to the max horizon of their experiment.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nestimates\nExtract estimated ATEs and confidence sequences.\n\n\nfit\nFit the MAD algorithm for the full time horizon.\n\n\nplot_ate\nPlot the ATE and CS paths for each arm of the experiment.\n\n\nplot_n\nPlot the total N assigned to each arm.\n\n\nplot_sample_assignment\nPlot sample assignment to arms across time\n\n\npull\nPerform one full iteration of the MAD algorithm.\n\n\nsummary\nPrint a summary of ATEs and confidence bands.\n\n\n\n\n\nMAD.estimates()\nExtract estimated ATEs and confidence sequences.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nA dataframe of ATE estimates and corresponding CS lower and upper bounds.\n\n\n\n\n\n\n\nMAD.fit(verbose=True)\nFit the MAD algorithm for the full time horizon.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nverbose\nbool\nWhether to print progress of the algorithm\nTrue\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nMAD.plot_ate()\nPlot the ATE and CS paths for each arm of the experiment.\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nplotnine.ggplot\n\n\n\n\n\n\n\n\nMAD.plot_n()\nPlot the total N assigned to each arm.\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nplotnine.ggplot\n\n\n\n\n\n\n\n\nMAD.plot_sample_assignment()\nPlot sample assignment to arms across time\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nplotnine.ggplot\n\n\n\n\n\n\n\n\nMAD.pull()\nPerform one full iteration of the MAD algorithm.\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nMAD.summary()\nPrint a summary of ATEs and confidence bands.\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone"
  },
  {
    "objectID": "reference/MAD.html#parameters",
    "href": "reference/MAD.html#parameters",
    "title": "MAD",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nbandit\nBandit\nThe underlying bandit algorithm on which the MAD design operates. This bandit class must implement several crucial methods/attributes. For more details on how to create a custom Bandit object, see the documentation of the pyssed.Bandit class.\nrequired\n\n\nalpha\nfloat\nThe size of the statistical test (testing for non-zero ATEs).\nrequired\n\n\ndelta\nCallable[[int], float]\nA function that generates the real-valued sequence delta_t in Liang and Bojinov (Definition 4 - Mixture Adaptive Design). This sequence determines the amount of random exploration that is infused into the bandit design, and it should converge to 0 slower than 1/t^(1/4) where t denotes the time step in {0, … n}. This function should intake an integer (t) and output a float (the corresponding delta_t).\nrequired\n\n\nt_star\nint\nThe time-step at which we want to optimize the CSs to be tightest. E.g. Liang and Bojinov set this to the max horizon of their experiment.\nrequired"
  },
  {
    "objectID": "reference/MAD.html#methods",
    "href": "reference/MAD.html#methods",
    "title": "MAD",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nestimates\nExtract estimated ATEs and confidence sequences.\n\n\nfit\nFit the MAD algorithm for the full time horizon.\n\n\nplot_ate\nPlot the ATE and CS paths for each arm of the experiment.\n\n\nplot_n\nPlot the total N assigned to each arm.\n\n\nplot_sample_assignment\nPlot sample assignment to arms across time\n\n\npull\nPerform one full iteration of the MAD algorithm.\n\n\nsummary\nPrint a summary of ATEs and confidence bands.\n\n\n\n\n\nMAD.estimates()\nExtract estimated ATEs and confidence sequences.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npandas.DataFrame\nA dataframe of ATE estimates and corresponding CS lower and upper bounds.\n\n\n\n\n\n\n\nMAD.fit(verbose=True)\nFit the MAD algorithm for the full time horizon.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nverbose\nbool\nWhether to print progress of the algorithm\nTrue\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nMAD.plot_ate()\nPlot the ATE and CS paths for each arm of the experiment.\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nplotnine.ggplot\n\n\n\n\n\n\n\n\nMAD.plot_n()\nPlot the total N assigned to each arm.\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nplotnine.ggplot\n\n\n\n\n\n\n\n\nMAD.plot_sample_assignment()\nPlot sample assignment to arms across time\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nplotnine.ggplot\n\n\n\n\n\n\n\n\nMAD.pull()\nPerform one full iteration of the MAD algorithm.\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nMAD.summary()\nPrint a summary of ATEs and confidence bands.\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone"
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Reference",
    "section": "",
    "text": "A class that implements the MAD experimental design\n\n\n\nMAD\nA class implementing Liang and Bojinov’s Mixture-Adaptive Design (MAD).\n\n\n\n\n\n\nA base class to design bandit algorithms that are compatible with MAD\n\n\n\nBandit\nAn abstract class for Bandit algorithms used in the MAD algorithm."
  },
  {
    "objectID": "reference/index.html#mad-experimental-design",
    "href": "reference/index.html#mad-experimental-design",
    "title": "Reference",
    "section": "",
    "text": "A class that implements the MAD experimental design\n\n\n\nMAD\nA class implementing Liang and Bojinov’s Mixture-Adaptive Design (MAD)."
  },
  {
    "objectID": "reference/index.html#bandit-base-class",
    "href": "reference/index.html#bandit-base-class",
    "title": "Reference",
    "section": "",
    "text": "A base class to design bandit algorithms that are compatible with MAD\n\n\n\nBandit\nAn abstract class for Bandit algorithms used in the MAD algorithm."
  }
]